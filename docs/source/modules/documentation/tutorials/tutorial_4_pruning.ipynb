{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Unstructured Pruning on Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning is a technique used to reduce the size and complexity of neural networks by removing unnecessary parameters (weights and connections) or structural components (neurons, filters, or layers). The goal is to create a smaller, more efficient model that maintains most of the original model's performance. The following benefits can be seen from pruning neural networks:\n",
    "\n",
    "- **Reduce model size**: Deep neural networks often have millions of parameters, leading to large storage requirements.\n",
    "\n",
    "- **Decrease inference time**: Fewer parameters mean fewer computations, resulting in faster predictions.\n",
    "\n",
    "- **Improve generalization**: Removing unnecessary connections can help prevent overfitting.\n",
    "\n",
    "- **Energy efficiency**: Smaller models require less energy to run, which is crucial for edge devices and mobile applications.\n",
    "\n",
    "Structured pruning removes entire structures (e.g., channels, filters, or layers) from the network, while unstructured pruning removes individual weights or connections from the network, regardless of their location. In this tutorial, we'll build on top of Tutorial 3 by taking the quantized Bert model and running Mase's unstructured pruning pass. After pruning, we'll run further fine tuning iterations to retain sequence classification accuracy in the pruned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are starting from scratch, you can create a MaseGraph for Bert by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n",
      "/Users/yz10513/anaconda3/envs/mase/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from chop import MaseGraph\n",
    "import chop.passes as passes\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "\n",
    "mg = MaseGraph(\n",
    "    model,\n",
    "    hf_input_names=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"labels\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "mg, _ = passes.init_metadata_analysis_pass(mg)\n",
    "mg, _ = passes.add_common_metadata_analysis_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have previously ran the tutorial on Quantization-Aware Training (QAT), run the following cell to import the fine tuned checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from chop import MaseGraph\n",
    "import torch\n",
    "\n",
    "mg = MaseGraph.from_checkpoint(f\"{Path.home()}/tutorial_3_qat\")\n",
    "# mg = MaseGraph.from_checkpoint(f\"/vol/bitbucket/nr722/adls_group_14/tutorial_3_qat\")\n",
    "# mg.model.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unstructured Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running pruning, let's evaluate the model accuracy on the IMDb dataset. If you're coming from Tutorial, this would be the same as the accuracy after Quantization Aware Training (QAT). If you've just initialized the model, this will likely be a random guess (i.e. around 50%), in which case pruning wouldn't have a significant effect on the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "Map: 100%|██████████| 50000/50000 [00:12<00:00, 4018.52 examples/s]\n",
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 03:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.838\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Evaluate accuracy\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the pruning pass, we pass the following pruning configuration dictionary, which defines the following parameters.\n",
    "\n",
    "- **Sparsity**: a value between 0 and 1, expressing the proportion of elements in the model that should be pruned (i.e. set to 0).\n",
    "\n",
    "- **Method**: several pruning methods are supported, including ``Random`` and ``L1-Norm``.\n",
    "\n",
    "- **Scope**: defines whether to consider each weight/activation tensor individually (``local``) or all tensors in the model (``global``) when obtaining statistics for pruning (e.g. absolute value threshold for pruning)\n",
    "\n",
    "We'll start by running random pruning with local scope, at a fixed sparsity. This may be suboptimal, but in future tutorials we'll see how to find optimal pruning and quantization configurations for a given model on a specified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import chop.passes as passes\n",
    "\n",
    "pruning_config = {\n",
    "    \"weight\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "    \"activation\": {\n",
    "        \"sparsity\": 0.5,\n",
    "        \"method\": \"l1-norm\",\n",
    "        \"scope\": \"local\",\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = passes.prune_transform_pass(mg, pass_args=pruning_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the effect of pruning on accuracy. It's likely to observe drops of around 10% or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [04:47<00:00, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.55512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    "    num_train_epochs=5,\n",
    ")\n",
    "\n",
    "# Evaluate accuracy\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome the drop in accuracy, we'll run a few finetuning epochs. This allows the model to adapt to the new pruning mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 500/15625 [00:56<21:55, 11.50it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.459, 'grad_norm': 1.4026139974594116, 'learning_rate': 4.8400000000000004e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1001/15625 [01:36<31:03,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4056, 'grad_norm': 0.9277871251106262, 'learning_rate': 4.6800000000000006e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 1500/15625 [02:15<12:55, 18.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4219, 'grad_norm': 1.443852186203003, 'learning_rate': 4.52e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2000/15625 [02:52<34:12,  6.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4059, 'grad_norm': 1.2503076791763306, 'learning_rate': 4.36e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 2500/15625 [03:25<11:55, 18.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4015, 'grad_norm': 0.6023377776145935, 'learning_rate': 4.2e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3000/15625 [03:53<11:18, 18.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4032, 'grad_norm': 1.3447505235671997, 'learning_rate': 4.0400000000000006e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 3501/15625 [04:20<12:08, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4193, 'grad_norm': 0.6158122420310974, 'learning_rate': 3.88e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 4002/15625 [04:46<12:50, 15.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4004, 'grad_norm': 1.2009944915771484, 'learning_rate': 3.72e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 4503/15625 [05:16<10:15, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3783, 'grad_norm': 0.8180735111236572, 'learning_rate': 3.56e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 5002/15625 [05:44<10:17, 17.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3933, 'grad_norm': 0.59749835729599, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 5502/15625 [06:12<11:11, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3883, 'grad_norm': 0.9686317443847656, 'learning_rate': 3.24e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6002/15625 [06:41<09:48, 16.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3871, 'grad_norm': 1.6825438737869263, 'learning_rate': 3.08e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 6503/15625 [07:08<08:24, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3808, 'grad_norm': 1.0123984813690186, 'learning_rate': 2.9199999999999998e-05, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 7001/15625 [07:33<08:33, 16.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3938, 'grad_norm': 0.5268100500106812, 'learning_rate': 2.7600000000000003e-05, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 7502/15625 [08:01<07:36, 17.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.391, 'grad_norm': 0.721001148223877, 'learning_rate': 2.6000000000000002e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 8001/15625 [08:27<08:42, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3842, 'grad_norm': 0.9280937314033508, 'learning_rate': 2.44e-05, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 8502/15625 [08:52<07:08, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4128, 'grad_norm': 1.1052242517471313, 'learning_rate': 2.2800000000000002e-05, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 9003/15625 [09:20<05:59, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.379, 'grad_norm': 0.6635761260986328, 'learning_rate': 2.12e-05, 'epoch': 2.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 9502/15625 [09:46<05:28, 18.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3885, 'grad_norm': 1.7871322631835938, 'learning_rate': 1.9600000000000002e-05, 'epoch': 3.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 10002/15625 [10:11<05:16, 17.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3713, 'grad_norm': 1.0901461839675903, 'learning_rate': 1.8e-05, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10502/15625 [10:36<04:28, 19.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.389, 'grad_norm': 0.6938749551773071, 'learning_rate': 1.6400000000000002e-05, 'epoch': 3.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 11003/15625 [11:02<04:19, 17.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3849, 'grad_norm': 0.6419057250022888, 'learning_rate': 1.48e-05, 'epoch': 3.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 11502/15625 [11:33<04:09, 16.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3755, 'grad_norm': 0.9091131687164307, 'learning_rate': 1.32e-05, 'epoch': 3.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 12001/15625 [11:58<03:40, 16.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3765, 'grad_norm': 0.7711085081100464, 'learning_rate': 1.16e-05, 'epoch': 3.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12503/15625 [12:24<02:43, 19.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3713, 'grad_norm': 0.4314064383506775, 'learning_rate': 1e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 13001/15625 [12:51<02:35, 16.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.375, 'grad_norm': 0.8700340390205383, 'learning_rate': 8.400000000000001e-06, 'epoch': 4.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 13502/15625 [13:16<02:01, 17.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3822, 'grad_norm': 0.7520729899406433, 'learning_rate': 6.800000000000001e-06, 'epoch': 4.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 14002/15625 [13:41<01:30, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3715, 'grad_norm': 0.5653247833251953, 'learning_rate': 5.2e-06, 'epoch': 4.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14500/15625 [14:07<00:55, 20.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3871, 'grad_norm': 1.1256822347640991, 'learning_rate': 3.6e-06, 'epoch': 4.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 15002/15625 [14:36<00:38, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3831, 'grad_norm': 0.8478624820709229, 'learning_rate': 2.0000000000000003e-06, 'epoch': 4.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 15502/15625 [15:02<00:06, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3749, 'grad_norm': 0.9598965644836426, 'learning_rate': 4.0000000000000003e-07, 'epoch': 4.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15625/15625 [15:08<00:00, 17.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 908.3575, 'train_samples_per_second': 137.611, 'train_steps_per_second': 17.201, 'train_loss': 0.3912585158691406, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15625, training_loss=0.3912585158691406, metrics={'train_runtime': 908.3575, 'train_samples_per_second': 137.611, 'train_steps_per_second': 17.201, 'total_flos': 0.0, 'train_loss': 0.3912585158691406, 'epoch': 5.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model accuracy after finetuning. We should see that the accuracy is reverted back to the original level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [02:02<00:00, 25.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.83624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/vol/bitbucket/nr722/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15625/15625 12:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.459800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.436300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.423700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.434300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.409200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.421800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.408200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.394900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.412600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.397700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.421200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.401700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.407700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.396700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.397300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.400800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.395200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.386200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.389300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.382700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.385700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.390100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.390100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.392100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.399000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.1, Method: random, Accuracy: 0.83564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/nr722/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15625/15625 13:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.671100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.588700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.531800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.502900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.498900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.482400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.494400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.461200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.468700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.458000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.469900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.460500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.456300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.450200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.473400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.448500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.468200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.451900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.452200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.454900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.441900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.455500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.444800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.440900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.442600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.452100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.447300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.3, Method: random, Accuracy: 0.80408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/nr722/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15625/15625 15:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.692900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.692600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.691900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.691900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.689600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.688300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.686200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.685400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.679300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.673000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.652200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.623700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.601200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.603700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.585200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.572300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.574900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.567100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.556200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.551600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.552000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.554000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.554300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.551800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.568700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.5, Method: random, Accuracy: 0.73232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/nr722/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15625/15625 17:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.692900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.693900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.692700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.692900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.693600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 03:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.7, Method: random, Accuracy: 0.5046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/nr722/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15625/15625 16:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.9, Method: random, Accuracy: 0.50424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n",
      "/vol/bitbucket/nr722/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15625/15625 03:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.397700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.392100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.411300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.388200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.397600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.398600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.376900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.368500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.375800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.377200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.376300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.358600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.374600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.365400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.359300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.387600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.371600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.353500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.362900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.357900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.349700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.340400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.352500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.343300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.364600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.356600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.351800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.1, Method: l1-norm, Accuracy: 0.85556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/nr722/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15625/15625 03:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.400100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.394100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.393900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.388900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.393500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.407400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.378700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.372000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.374600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.383000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.376600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.366100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.362700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.387600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.365700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.359100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.364900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.365800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.361700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.359900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.358900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.341200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.353400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.348300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.360500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.365200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.359500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.3, Method: l1-norm, Accuracy: 0.84988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/nr722/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15625/15625 03:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.455800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.414500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.427700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.411600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.406900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.413800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.402500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.394000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.400200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.387100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.395200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.394100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.386500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.415200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.389700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.388200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.391500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.392200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.381900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.387400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.376400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.393400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.387800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.388100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.390500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.390600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.5, Method: l1-norm, Accuracy: 0.8302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/nr722/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15625/15625 03:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.593400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.563100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.522700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.495700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.469700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.445200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.439100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.446700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.434200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.440200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.433300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.455600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.426900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.427300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.431600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.429900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.425900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.420900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.416100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.428300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.420100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.435700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.418000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_0_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_query\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_key\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_self_value\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_attention_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_intermediate_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_encoder_layer_1_output_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: bert_pooler_dense\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mPruning module: classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.7, Method: l1-norm, Accuracy: 0.8058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/nr722/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15625' max='15625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15625/15625 03:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.692600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.692900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.694400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.692600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.692400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.693500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.692100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.691700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.691700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.690700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.690600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.691600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.691200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.689700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.690500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.691600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.690100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.689300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.689300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.689500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.690500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.9, Method: l1-norm, Accuracy: 0.54376\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take your best obtained model from Task 1 and rerun the pruning procedure, this time varying the sparsity from 0.1 to 0.9.\n",
    "\n",
    "# Plot a figure where the x-axis is the sparsity and the y-axis is the highest achieved accuracy on the IMDb dataset, following the procedure in Tutorial 4.\n",
    "\n",
    "# Plot separate curves for Random and L1-Norm methods to evaluate the effect of different pruning strategies.\n",
    "\n",
    "from pathlib import Path\n",
    "from chop import MaseGraph\n",
    "import chop.passes as passes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "methods = [\"random\", \"l1-norm\"]\n",
    "sparsities = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "for method in methods:\n",
    "    accuracies = []\n",
    "    for sparsity in sparsities:\n",
    "        mg = MaseGraph.from_checkpoint(f\"/vol/bitbucket/nr722/adls_group_14/tutorial_3_qat\")\n",
    "\n",
    "        pruning_config = {\n",
    "            \"weight\": {\n",
    "                \"sparsity\": sparsity,\n",
    "                \"method\": method,\n",
    "                \"scope\": \"local\",\n",
    "            },\n",
    "            \"activation\": {\n",
    "                \"sparsity\": sparsity,\n",
    "                \"method\": method,\n",
    "                \"scope\": \"local\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "        mg, _ = passes.prune_transform_pass(mg, pass_args=pruning_config)\n",
    "        mg.model.to(\"cuda\")\n",
    "        trainer = get_trainer(\n",
    "            model=mg.model,\n",
    "            tokenized_dataset=dataset,\n",
    "            tokenizer=tokenizer,\n",
    "            evaluate_metric=\"accuracy\",\n",
    "            num_train_epochs=5,\n",
    "            use_mps_device=False,\n",
    "        )\n",
    "\n",
    "        # Finetune the pruned model to recover accuracy\n",
    "        trainer.train()\n",
    "        eval_results = trainer.evaluate()\n",
    "        accuracies.append(eval_results[\"eval_accuracy\"])\n",
    "        print(f\"Sparsity: {sparsity}, Method: {method}, Accuracy: {eval_results['eval_accuracy']}\")\n",
    "\n",
    "    plt.plot(sparsities, accuracies, marker=\"o\", label=method)\n",
    "\n",
    "plt.xlabel(\"Sparsity\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Pruning sparsity vs IMDb accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Method: l1-norm\n",
      "sparsities = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
      "accuracies = [0.85556, 0.84988, 0.8302, 0.8058, 0.54376]\n",
      "pairs = [(0.1, 0.85556), (0.3, 0.84988), (0.5, 0.8302), (0.7, 0.8058), (0.9, 0.54376)]\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f\"Method: {method}\")\n",
    "print(\"sparsities =\", sparsities)\n",
    "print(\"accuracies =\", accuracies)\n",
    "print(\"pairs =\", list(zip(sparsities, accuracies)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
