{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Running Quantization-Aware Training (QAT) on Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll build on top of Tutorial 2 by taking the Bert model fine tuned for sequence classification and running Mase's quantization pass. First, we'll run simple Post-Training Quantization (PTQ) and see how much accuracy drops. Then, we'll run some further training iterations of the quantized model (i.e. QAT) and see whether the accuracy of the trained quantized model approaches the accuracy of the original (full-precision) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are starting from scratch, you can create a MaseGraph for Bert by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/neil/adls/adls_group_14/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4536e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3174e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7116,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3929, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4198e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6226e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1798e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1239e-02,  3.8892e-01,  ...,  1.3441e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1300e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6854e-01, -8.0783e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6711e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1035e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[0.1385, 0.0325],\n",
      "        [0.1314, 0.0993]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from chop import MaseGraph\n",
    "import chop.passes as passes\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "\n",
    "mg = MaseGraph(\n",
    "    model,\n",
    "    hf_input_names=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"labels\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "mg, _ = passes.init_metadata_analysis_pass(mg)\n",
    "mg, _ = passes.add_common_metadata_analysis_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have previously ran the tutorial on LoRA Finetuning, run the following cell to import the fine tuned checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from chop import MaseGraph\n",
    "\n",
    "mg = MaseGraph.from_checkpoint(f\"{Path.home()}/tutorial_2_lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Training Quantization (PTQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we simply quantize the model and evaluate the effect in its accuracy. First, let's evaluate the model accuracy before quantization (if you're coming from Tutorial 2, this should be the same as the post-LoRA evaluation accuracy). As seen in Tutorial 2, we can use the `get_tokenized_dataset` and `get_trainer` utilities to generate a HuggingFace `Trainer` instance for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "Map: 100%|| 25000/25000 [00:04<00:00, 5495.69 examples/s]\n",
      "Map: 100%|| 25000/25000 [00:05<00:00, 4766.71 examples/s]\n",
      "Map: 100%|| 50000/50000 [00:11<00:00, 4184.19 examples/s]\n",
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:27]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.83244\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Evaluate accuracy\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the quantization pass, we pass a quantization configuration dictionary as argument. This defines the quantization mode, numerical format and precision for each operator in the graph. We'll run the quantization in \"by type\" mode, meaning nodes are quantized according to their `mase_op`. Other modes include by name and by regex name. We'll quantize all activations, weights and biases in the model to fixed-point with the same precision. This may be sub-optimal, but works as an example. In future tutorials, we'll see how to run the `search` flow in `Mase` to find optimal quantization configurations to minimize accuracy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chop.passes as passes\n",
    "\n",
    "quantization_config = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": None,\n",
    "        }\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = passes.quantize_transform_pass(\n",
    "    mg,\n",
    "    pass_args=quantization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the immediate effect of quantization on the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 19:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.80492\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    ")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the current checkpoint for future reference (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to /home/neil/tutorial_3_ptq.pt, /home/neil/tutorial_3_ptq.mz\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to /home/neil/tutorial_3_ptq.pt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaving full model format\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseMetadata to /home/neil/tutorial_3_ptq.mz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "mg.export(f\"{Path.home()}/tutorial_3_ptq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization-Aware Training (QAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have seen in the last section that quantization can lead to a significant drop in accuracy. Next, we'll run QAT to evaluate whether this performance gap can be reduced. To run QAT in Mase, all you need to do is include the model back in your training loop after running the quantization pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 09:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.424500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.405100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.414700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.397700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.396000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.838\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the accuracy of the quantized model can match (or sometimes exceed) the full precision model, with a much lower memory requirement to store the weights. Finally, save the final checkpoint for future tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to /home/neil/tutorial_3_qat.pt, /home/neil/tutorial_3_qat.mz\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to /home/neil/tutorial_3_qat.pt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaving full model format\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseMetadata to /home/neil/tutorial_3_qat.mz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "mg.export(f\"{Path.home()}/tutorial_3_qat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Precision vs. Accuracy\n",
    "\n",
    "In Tutorial 3, we quantized every Linear layer in the model to a fixed configuration. Now, we explore a range of fixed point widths from 4 to 32 to see their effect on accuracy. We will plot separate curves for PTQ and QAT at each precision to show the effect of post-quantization finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating bit width: 4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4536e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3174e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7116,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3929, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4198e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6226e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1798e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1239e-02,  3.8892e-01,  ...,  1.3441e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1300e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6854e-01, -8.0783e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6711e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1035e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[0.0273, 0.2205],\n",
      "        [0.0204, 0.2484]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluating PTQ accuracy...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 26:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PTQ Accuracy for 4 bits: 0.5000\n",
      "  Running QAT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 15:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  QAT Accuracy for 4 bits: 0.5000\n",
      "--- Evaluating bit width: 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4536e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3174e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7116,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3929, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4198e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6226e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1798e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1239e-02,  3.8892e-01,  ...,  1.3441e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1300e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6854e-01, -8.0783e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6711e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1035e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[0.0273, 0.2205],\n",
      "        [0.0204, 0.2484]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "  Evaluating PTQ accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 17:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PTQ Accuracy for 8 bits: 0.5000\n",
      "  Running QAT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 10:46, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.483300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.426500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.371300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.373300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  QAT Accuracy for 8 bits: 0.8571\n",
      "--- Evaluating bit width: 12 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4536e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3174e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7116,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3929, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4198e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6226e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1798e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1239e-02,  3.8892e-01,  ...,  1.3441e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1300e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6854e-01, -8.0783e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6711e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1035e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[0.0273, 0.2205],\n",
      "        [0.0204, 0.2484]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "  Evaluating PTQ accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 16:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PTQ Accuracy for 12 bits: 0.4342\n",
      "  Running QAT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 09:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.629200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.412800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.372700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.363600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.368300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  QAT Accuracy for 12 bits: 0.8578\n",
      "--- Evaluating bit width: 16 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4536e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3174e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7116,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3929, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4198e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6226e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1798e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1239e-02,  3.8892e-01,  ...,  1.3441e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1300e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6854e-01, -8.0783e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6711e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1035e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[0.0273, 0.2205],\n",
      "        [0.0204, 0.2484]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "  Evaluating PTQ accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 15:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PTQ Accuracy for 16 bits: 0.4768\n",
      "  Running QAT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 09:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.631300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.446100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.368800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.355600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.368400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  QAT Accuracy for 16 bits: 0.8586\n",
      "--- Evaluating bit width: 24 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4536e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3174e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7116,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3929, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4198e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6226e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1798e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1239e-02,  3.8892e-01,  ...,  1.3441e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1300e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6854e-01, -8.0783e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6711e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1035e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[0.0273, 0.2205],\n",
      "        [0.0204, 0.2484]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "  Evaluating PTQ accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 16:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PTQ Accuracy for 24 bits: 0.4669\n",
      "  Running QAT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 09:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.632700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.444700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.409700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.367100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.358500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.369300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  QAT Accuracy for 24 bits: 0.8589\n",
      "--- Evaluating bit width: 32 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4536e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3174e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7116,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3929, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3441e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8836e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4198e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6226e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0707e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1798e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1239e-02,  3.8892e-01,  ...,  1.3441e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1300e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6854e-01, -8.0783e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6711e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1035e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3792e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5677e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4396e-02, -6.9033e-02],\n",
      "          [-1.0678e+00,  9.0884e-02, -4.5400e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6669e-03, -5.7118e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8034e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3362e-01,  1.5919e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1642e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6174e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[0.0273, 0.2205],\n",
      "        [0.0204, 0.2484]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n",
      "  Evaluating PTQ accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 16:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PTQ Accuracy for 32 bits: 0.4675\n",
      "  Running QAT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 09:28, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.628700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.439300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.408600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.365300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.356600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.367400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  QAT Accuracy for 32 bits: 0.8597\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "import chop.passes as passes\n",
    "from chop.tools import get_trainer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Define bit widths to explore\n",
    "bit_widths = [4, 8, 12, 16, 24, 32]\n",
    "ptq_accuracies = []\n",
    "qat_accuracies = []\n",
    "\n",
    "for width in bit_widths:\n",
    "    print(f\"--- Evaluating bit width: {width} ---\")\n",
    "    # For simplicity, we use half of the bit-width for the fractional part\n",
    "    frac_width = width // 2\n",
    "    \n",
    "    # Initialize a fresh model and MaseGraph for each bit-width\n",
    "    model_fp = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "    model_fp.config.problem_type = \"single_label_classification\"\n",
    "    \n",
    "    mg_loop = MaseGraph(\n",
    "        model_fp,\n",
    "        hf_input_names=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    )\n",
    "    mg_loop, _ = passes.init_metadata_analysis_pass(mg_loop)\n",
    "    mg_loop, _ = passes.add_common_metadata_analysis_pass(mg_loop)\n",
    "    \n",
    "    quantization_config = {\n",
    "        \"by\": \"type\",\n",
    "        \"default\": {\"config\": {\"name\": None}},\n",
    "        \"linear\": {\n",
    "            \"config\": {\n",
    "                \"name\": \"integer\",\n",
    "                \"data_in_width\": width, \n",
    "                \"data_in_frac_width\": frac_width,\n",
    "                \"weight_width\": width, \n",
    "                \"weight_frac_width\": frac_width,\n",
    "                \"bias_width\": width, \n",
    "                \"bias_frac_width\": frac_width,\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    # Apply PTQ\n",
    "    mg_loop, _ = passes.quantize_transform_pass(mg_loop, pass_args=quantization_config)\n",
    "    \n",
    "    trainer_loop = get_trainer(\n",
    "        model=mg_loop.model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "    )\n",
    "    \n",
    "    print(f\"  Evaluating PTQ accuracy...\")\n",
    "    ptq_res = trainer_loop.evaluate()\n",
    "    ptq_acc = ptq_res[\"eval_accuracy\"]\n",
    "    ptq_accuracies.append(ptq_acc)\n",
    "    print(f\"  PTQ Accuracy for {width} bits: {ptq_acc:.4f}\")\n",
    "    \n",
    "    # Apply QAT (Fine-tuning)\n",
    "    print(f\"  Running QAT training...\")\n",
    "    trainer_loop.train()\n",
    "    qat_res = trainer_loop.evaluate()\n",
    "    qat_acc = qat_res[\"eval_accuracy\"]\n",
    "    qat_accuracies.append(qat_acc)\n",
    "    print(f\"  QAT Accuracy for {width} bits: {qat_acc:.4f}\")\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(bit_widths, ptq_accuracies, label='PTQ Accuracy', marker='o', linestyle='--', color='blue')\n",
    "plt.plot(bit_widths, qat_accuracies, label='QAT Accuracy', marker='s', linestyle='-', color='red')\n",
    "plt.xlabel('Fixed Point Width (bits)')\n",
    "plt.ylabel('Highest Achieved Accuracy')\n",
    "plt.title('Accuracy vs. Precision: PTQ vs QAT (IMDb Dataset)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(bit_widths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bit_widths = [4, 8, 12, 16, 24, 32] \n",
      "ptq_accuracies = [0.5, 0.5, 0.4342, 0.47676, 0.46692, 0.46748]\n",
      "qat_accuracies = [0.5, 0.85708, 0.8578, 0.85856, 0.85892, 0.85968]\n"
     ]
    }
   ],
   "source": [
    "print(f'bit_widths = {bit_widths} \\nptq_accuracies = {ptq_accuracies}\\nqat_accuracies = {qat_accuracies}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating bit width: 4 ---\n",
      "  Evaluating PTQ accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 20:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running QAT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 12:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Width 4 -> PTQ: 0.5000, QAT: 0.5000\n",
      "--- Evaluating bit width: 8 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluating PTQ accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 14:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running QAT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 07:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.424500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.405100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.414700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.397700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.396000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Width 8 -> PTQ: 0.8049, QAT: 0.8380\n",
      "--- Evaluating bit width: 12 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluating PTQ accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 14:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running QAT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 07:43, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.412800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.394900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.378200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.388400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Width 12 -> PTQ: 0.8318, QAT: 0.8404\n",
      "--- Evaluating bit width: 16 ---\n",
      "  Evaluating PTQ accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 13:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running QAT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 07:41, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.412200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.386900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Width 16 -> PTQ: 0.8327, QAT: 0.8406\n",
      "--- Evaluating bit width: 24 ---\n",
      "  Evaluating PTQ accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 14:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running QAT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 07:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.396100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.406900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.386700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Width 24 -> PTQ: 0.8324, QAT: 0.8410\n",
      "--- Evaluating bit width: 32 ---\n",
      "  Evaluating PTQ accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neil/adls/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 21:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running QAT training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 13:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.396100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.406900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.379300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.386000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.386600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Width 32 -> PTQ: 0.8325, QAT: 0.8411\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "import chop.passes as passes\n",
    "from chop.tools import get_trainer\n",
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "# Define bit widths to explore\n",
    "bit_widths = [4, 8, 12, 16, 24, 32]\n",
    "ptq_accuracies = []\n",
    "qat_accuracies = []\n",
    "checkpoint_path = f\"{Path.home()}/tutorial_2_lora\"\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "for width in bit_widths:\n",
    "    print(f\"--- Evaluating bit width: {width} ---\")\n",
    "    # Load model fresh from checkpoint for each bit-width\n",
    "    mg_loop = MaseGraph.from_checkpoint(checkpoint_path)\n",
    "    frac_width = width // 2\n",
    "    \n",
    "    quantization_config = {\n",
    "        \"by\": \"type\",\n",
    "        \"default\": {\"config\": {\"name\": None}},\n",
    "        \"linear\": {\n",
    "            \"config\": {\n",
    "                \"name\": \"integer\",\n",
    "                \"data_in_width\": width, \n",
    "                \"data_in_frac_width\": frac_width,\n",
    "                \"weight_width\": width, \n",
    "                \"weight_frac_width\": frac_width,\n",
    "                \"bias_width\": width, \n",
    "                \"bias_frac_width\": frac_width,\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    # 1. Apply PTQ\n",
    "    mg_loop, _ = passes.quantize_transform_pass(mg_loop, pass_args=quantization_config)\n",
    "    \n",
    "    trainer_loop = get_trainer(\n",
    "        model=mg_loop.model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "    )\n",
    "    \n",
    "    print(f\"  Evaluating PTQ accuracy...\")\n",
    "    ptq_acc = trainer_loop.evaluate()[\"eval_accuracy\"]\n",
    "    ptq_accuracies.append(ptq_acc)\n",
    "    \n",
    "    # 2. Apply QAT\n",
    "    print(f\"  Running QAT training...\")\n",
    "    trainer_loop.train()\n",
    "    qat_acc = trainer_loop.evaluate()[\"eval_accuracy\"]\n",
    "    qat_accuracies.append(qat_acc)\n",
    "    print(f\"  Width {width} -> PTQ: {ptq_acc:.4f}, QAT: {qat_acc:.4f}\")\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(bit_widths, ptq_accuracies, label='PTQ Accuracy', marker='o', linestyle='--')\n",
    "plt.plot(bit_widths, qat_accuracies, label='QAT Accuracy', marker='s', linestyle='-')\n",
    "plt.xlabel('Fixed Point Width (bits)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Precision: PTQ vs QAT (IMDb)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(bit_widths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'bit_widths {bit_widths}')\n",
    "print(f'ptq_accuracies {ptq_accuracies}')\n",
    "print(f'qat_accuracies{qat_accuracies}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
