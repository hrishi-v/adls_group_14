{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Running Quantization-Aware Training (QAT) on Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll build on top of Tutorial 2 by taking the Bert model fine tuned for sequence classification and running Mase's quantization pass. First, we'll run simple Post-Training Quantization (PTQ) and see how much accuracy drops. Then, we'll run some further training iterations of the quantized model (i.e. QAT) and see whether the accuracy of the trained quantized model approaches the accuracy of the original (full-precision) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"prajjwal1/bert-tiny\"\n",
    "tokenizer_checkpoint = \"bert-base-uncased\"\n",
    "dataset_name = \"imdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are starting from scratch, you can create a MaseGraph for Bert by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "`past_key_values` were not specified as input names, but model.config.use_cache = True. Setting model.config.use_cache = False.\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mGetting dummy input for prajjwal1/bert-tiny.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[ 101, 9932, 2089, 2202, 2058, 1996, 2088, 2028, 2154,  102],\n",
      "        [ 101, 2023, 2003, 2339, 2017, 2323, 4553, 4748, 4877,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]])\n",
      "tensor([[[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-1.1766,  1.2879, -1.0986,  ...,  0.4749, -0.5899,  0.8746],\n",
      "         [-2.0560,  0.7748, -0.8909,  ..., -0.4034,  0.5352, -1.3657],\n",
      "         ...,\n",
      "         [ 0.2317, -0.7896,  0.9634,  ..., -0.8037,  0.4834, -0.5868],\n",
      "         [ 0.0243, -1.0235, -1.2771,  ..., -2.2378,  1.8530,  0.1558],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]],\n",
      "\n",
      "        [[ 0.7973,  0.0109, -8.8405,  ...,  1.4170,  0.1046, -0.1551],\n",
      "         [-2.6940,  0.6198, -0.4564,  ..., -1.4367, -1.5705, -3.1260],\n",
      "         [-1.7524,  0.8535, -0.2155,  ..., -0.5222, -1.2430, -1.7199],\n",
      "         ...,\n",
      "         [-0.0347,  0.7446,  1.4462,  ..., -1.1578, -2.6197,  0.2612],\n",
      "         [ 2.4334, -0.3068,  0.8250,  ...,  0.1475,  0.1790,  2.2907],\n",
      "         [-1.3637,  0.7055, -0.2177,  ...,  0.3557, -0.3971, -0.3107]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -8.1892e-01,\n",
      "           1.1978e+00,  2.1808e+00],\n",
      "         [ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -6.3025e-01,\n",
      "          -1.5967e-01,  1.3284e+00],\n",
      "         ...,\n",
      "         [ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ..., -3.0983e-01,\n",
      "          -1.2971e-01,  1.1265e+00],\n",
      "         [ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ..., -1.3174e+00,\n",
      "           2.2258e-01,  8.8157e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]],\n",
      "\n",
      "        [[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ...,  1.4757e-01,\n",
      "           1.8900e-01,  2.8282e-01],\n",
      "         [-4.4781e-01, -7.9224e-01, -2.1741e+00,  ..., -5.9181e-01,\n",
      "           1.4373e+00,  2.4267e+00],\n",
      "         [-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -5.9773e-01,\n",
      "          -3.0482e-01,  1.4038e+00],\n",
      "         ...,\n",
      "         [ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.1508e+00,\n",
      "           7.5490e-01,  8.2911e-01],\n",
      "         [ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -1.5233e+00,\n",
      "          -6.0733e-01,  3.3097e-01],\n",
      "         [-3.7517e-01,  1.5191e+00, -2.6796e-01,  ..., -1.6159e+00,\n",
      "           7.2677e-02,  1.1724e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-3.5020e-02, -6.1047e-02, -1.0465e-01,  ..., -2.0138e+00,\n",
      "            4.5529e-01, -7.8171e-01],\n",
      "          [ 1.1969e+00,  1.6337e+00,  2.5047e-01,  ..., -8.1892e-01,\n",
      "            1.1978e+00,  2.1808e+00]],\n",
      "\n",
      "         [[ 4.3982e-01, -1.9602e+00, -6.8830e-01,  ..., -2.2501e-01,\n",
      "            7.2290e-02, -1.8290e+00],\n",
      "          [ 8.9952e-01,  1.0029e+00,  7.4536e-04,  ..., -6.3025e-01,\n",
      "           -1.5967e-01,  1.3284e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4783e+00,  1.0907e-01, -1.5222e+00,  ...,  1.1867e+00,\n",
      "           -1.3561e+00,  6.5158e-01],\n",
      "          [ 9.5466e-01,  4.5887e-01,  7.8078e-01,  ..., -3.0983e-01,\n",
      "           -1.2971e-01,  1.1265e+00]],\n",
      "\n",
      "         [[ 1.5890e+00, -1.6859e+00,  7.8703e-01,  ...,  6.5467e-01,\n",
      "           -6.8451e-01,  6.5081e-01],\n",
      "          [ 7.0729e-01,  1.4499e+00, -1.5089e-01,  ..., -1.3174e+00,\n",
      "            2.2258e-01,  8.8157e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7740e-01,  2.5482e-03, -5.2921e-01,  ..., -5.2614e-01,\n",
      "           -3.5687e-01, -2.6793e-01],\n",
      "          [ 2.0335e-01, -5.4534e-01,  3.0686e-01,  ...,  1.4757e-01,\n",
      "            1.8900e-01,  2.8282e-01]],\n",
      "\n",
      "         [[-4.4781e-01, -7.9224e-01, -2.1741e+00,  ...,  1.7508e+00,\n",
      "           -3.6708e-01, -1.3251e+00],\n",
      "          [ 7.9208e-01, -1.3537e-01,  2.3756e-01,  ..., -5.9181e-01,\n",
      "            1.4373e+00,  2.4267e+00]],\n",
      "\n",
      "         [[-2.5942e-01,  9.7163e-01, -3.2928e+00,  ..., -9.6646e-01,\n",
      "           -4.8876e-01, -1.4426e+00],\n",
      "          [ 1.0250e+00, -6.9093e-01, -1.2734e+00,  ..., -5.9773e-01,\n",
      "           -3.0482e-01,  1.4038e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1575e-02,  3.5218e-01, -3.8926e-01,  ..., -1.2252e-02,\n",
      "            1.0394e+00,  4.2402e-01],\n",
      "          [-4.7386e-01,  2.6401e+00,  1.7024e+00,  ..., -1.1508e+00,\n",
      "            7.5490e-01,  8.2911e-01]],\n",
      "\n",
      "         [[ 1.6107e+00,  6.8170e-02,  9.2537e-01,  ..., -6.1665e-01,\n",
      "            2.7627e-01, -1.2083e+00],\n",
      "          [ 9.3395e-01, -9.7541e-01, -2.5442e-02,  ..., -1.5233e+00,\n",
      "           -6.0733e-01,  3.3097e-01]],\n",
      "\n",
      "         [[-3.7517e-01,  1.5191e+00, -2.6796e-01,  ...,  3.3130e-01,\n",
      "           -3.2756e-01, -6.3130e-01],\n",
      "          [ 8.6773e-01,  2.0996e-01, -3.4332e-01,  ..., -1.6159e+00,\n",
      "            7.2677e-02,  1.1724e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-0.5842,  0.9588,  1.5642,  ..., -1.0731, -0.7330,  0.3132],\n",
      "         [-0.8601, -1.3756,  0.5042,  ..., -0.0476,  0.2650,  1.2150],\n",
      "         ...,\n",
      "         [ 0.0520,  1.1719, -1.5471,  ..., -0.7894,  0.1419,  1.6964],\n",
      "         [ 0.7654, -1.5053, -0.4142,  ..., -1.4622, -0.8975,  1.4576],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]],\n",
      "\n",
      "        [[-0.1709,  0.5230, -0.8713,  ..., -1.3382,  0.5892,  0.4026],\n",
      "         [-1.3806,  0.2626, -0.5207,  ..., -1.6714, -0.0554,  1.0225],\n",
      "         [-1.7116,  1.8788, -2.5695,  ..., -0.6958,  0.5728,  0.5461],\n",
      "         ...,\n",
      "         [-1.3246,  1.2196, -0.3034,  ..., -1.1955, -0.6708,  0.5128],\n",
      "         [ 0.9854,  0.8260,  0.2892,  ..., -0.6428,  0.3637,  0.4339],\n",
      "         [-1.2008, -0.6008, -1.4608,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-0.5842,  0.9588,  1.5642,  ..., -1.5431,  0.4999, -1.1350],\n",
      "          [ 0.9615,  0.8694,  0.0998,  ..., -1.0731, -0.7330,  0.3132]],\n",
      "\n",
      "         [[-0.8601, -1.3756,  0.5042,  ...,  0.9764, -0.8321, -1.0204],\n",
      "          [ 1.5175,  1.1454,  0.7791,  ..., -0.0476,  0.2650,  1.2150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0520,  1.1719, -1.5471,  ...,  1.9402, -1.1294,  0.4793],\n",
      "          [ 1.0053,  0.8099,  1.6415,  ..., -0.7894,  0.1419,  1.6964]],\n",
      "\n",
      "         [[ 0.7654, -1.5053, -0.4142,  ...,  1.7455, -0.7326,  1.5248],\n",
      "          [ 1.0806,  1.1457,  2.2163,  ..., -1.4622, -0.8975,  1.4576]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]],\n",
      "\n",
      "\n",
      "        [[[-0.1709,  0.5230, -0.8713,  ...,  0.4365,  0.6238, -0.9414],\n",
      "          [-1.3731,  1.1521,  0.1321,  ..., -1.3382,  0.5892,  0.4026]],\n",
      "\n",
      "         [[-1.3806,  0.2626, -0.5207,  ...,  1.6517, -0.2316, -1.3171],\n",
      "          [ 0.6812, -0.0090,  0.3803,  ..., -1.6714, -0.0554,  1.0225]],\n",
      "\n",
      "         [[-1.7116,  1.8788, -2.5695,  ...,  0.4927, -0.4850, -1.0645],\n",
      "          [ 1.2646,  1.6481,  0.9055,  ..., -0.6958,  0.5728,  0.5461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3246,  1.2196, -0.3034,  ...,  1.2747,  1.2353,  0.2825],\n",
      "          [ 1.5373,  0.8648,  0.6062,  ..., -1.1955, -0.6708,  0.5128]],\n",
      "\n",
      "         [[ 0.9854,  0.8260,  0.2892,  ...,  1.3848, -0.0103, -1.0700],\n",
      "          [ 1.3827,  2.9809,  0.0276,  ..., -0.6428,  0.3637,  0.4339]],\n",
      "\n",
      "         [[-1.2008, -0.6008, -1.4608,  ...,  2.0905,  1.8849, -1.5708],\n",
      "          [ 1.9999,  0.3493, -0.8524,  ..., -1.2105, -0.4289,  0.3827]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-1.1465, -1.5578, -0.6984,  ...,  1.0310,  0.4824, -0.2291],\n",
      "         [-1.0361, -1.8192, -2.3055,  ...,  1.5286, -1.5941,  1.1762],\n",
      "         ...,\n",
      "         [-0.7992,  0.0886,  0.4887,  ..., -1.7941,  0.4835,  1.3780],\n",
      "         [-1.4692, -0.9135, -0.2802,  ..., -0.9691,  0.3500,  1.8863],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]],\n",
      "\n",
      "        [[-0.0123,  0.5761,  0.2209,  ..., -0.1027,  1.1061, -2.5200],\n",
      "         [-0.3700, -1.9754, -0.7315,  ...,  0.2293,  0.6996,  3.1299],\n",
      "         [-0.6252,  0.2879, -1.4036,  ..., -2.0560, -2.4623, -0.9584],\n",
      "         ...,\n",
      "         [-1.1306, -1.4343, -1.4422,  ..., -1.6115, -0.0475,  1.3975],\n",
      "         [-0.9816, -1.4909, -1.0086,  ..., -0.9284,  0.5260,  1.5330],\n",
      "         [-0.5760, -0.0452,  0.4230,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-1.1465, -1.5578, -0.6984,  ...,  0.0289, -2.1112, -0.8728],\n",
      "          [ 0.6506, -1.6966,  1.4463,  ...,  1.0310,  0.4824, -0.2291]],\n",
      "\n",
      "         [[-1.0361, -1.8192, -2.3055,  ..., -0.2195, -1.1732,  0.3182],\n",
      "          [-0.5841, -0.0227,  3.0901,  ...,  1.5286, -1.5941,  1.1762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.7992,  0.0886,  0.4887,  ...,  0.7859, -1.0127, -0.2676],\n",
      "          [-0.3055,  0.6270, -3.0705,  ..., -1.7941,  0.4835,  1.3780]],\n",
      "\n",
      "         [[-1.4692, -0.9135, -0.2802,  ...,  0.1197, -0.7532,  0.0731],\n",
      "          [ 0.6096, -1.0893, -0.6959,  ..., -0.9691,  0.3500,  1.8863]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]],\n",
      "\n",
      "\n",
      "        [[[-0.0123,  0.5761,  0.2209,  ..., -0.1457, -0.7538,  0.1761],\n",
      "          [-0.0705,  0.9215,  0.7990,  ..., -0.1027,  1.1061, -2.5200]],\n",
      "\n",
      "         [[-0.3700, -1.9754, -0.7315,  ...,  0.5756, -1.5559,  0.0326],\n",
      "          [ 1.4229,  2.3970, -0.4516,  ...,  0.2293,  0.6996,  3.1299]],\n",
      "\n",
      "         [[-0.6252,  0.2879, -1.4036,  ...,  0.5306, -0.5608,  1.1861],\n",
      "          [-2.5980,  0.2673,  3.3016,  ..., -2.0560, -2.4623, -0.9584]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1306, -1.4343, -1.4422,  ...,  0.3918, -1.5336, -0.5026],\n",
      "          [ 1.8587,  0.8501, -1.2402,  ..., -1.6115, -0.0475,  1.3975]],\n",
      "\n",
      "         [[-0.9816, -1.4909, -1.0086,  ...,  0.2956,  0.0351, -1.0685],\n",
      "          [-0.6594, -0.0133, -1.1863,  ..., -0.9284,  0.5260,  1.5330]],\n",
      "\n",
      "         [[-0.5760, -0.0452,  0.4230,  ...,  0.8851,  0.3078,  0.8106],\n",
      "          [-1.1804,  0.9512,  0.3169,  ..., -0.7179, -0.7858,  1.6879]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          ...,\n",
      "          [-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026]],\n",
      "\n",
      "         [[-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990],\n",
      "          ...,\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          ...,\n",
      "          [-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201]],\n",
      "\n",
      "         [[ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721],\n",
      "          ...,\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[-0.5911, -0.4682, -0.4314,  ...,  0.0366, -1.0405, -0.0579],\n",
      "          [-0.3266,  0.6360,  0.0214,  ...,  0.1677,  0.3883,  0.4382]],\n",
      "\n",
      "         [[-1.1141, -1.4785, -0.6477,  ...,  0.0631, -1.9950, -0.7912],\n",
      "          [-0.6299,  0.6012,  0.7379,  ...,  0.2989, -0.1569,  0.9508]],\n",
      "\n",
      "         [[-0.7059, -0.9954, -1.3923,  ..., -0.1557, -0.9998,  0.2774],\n",
      "          [-0.4097,  0.6374, -0.1589,  ...,  0.0258, -0.0364,  0.9990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6300,  0.1252,  0.3486,  ...,  0.5692, -0.9417, -0.1399],\n",
      "          [-0.0088,  0.1378, -0.4819,  ..., -0.1261,  0.2908,  1.0980]],\n",
      "\n",
      "         [[-1.0593, -0.6395, -0.3343,  ...,  0.0571, -0.7842,  0.1042],\n",
      "          [-0.5584,  0.9932, -0.1105,  ...,  0.2486,  0.4005,  0.6046]],\n",
      "\n",
      "         [[-0.2081,  0.2785,  0.0613,  ..., -0.0353, -0.8389, -0.0026],\n",
      "          [-0.4516,  0.8092, -0.0513,  ...,  0.1182,  0.4294,  0.4781]]],\n",
      "\n",
      "\n",
      "        [[[-0.6850, -0.2168, -0.6087,  ...,  0.1402, -0.7267, -0.1502],\n",
      "          [ 0.0907,  0.7927, -0.0524,  ..., -0.4610, -0.4295,  0.4391]],\n",
      "\n",
      "         [[-0.2084, -0.1325, -0.1151,  ...,  0.0938, -0.8963,  0.1296],\n",
      "          [-0.2352,  1.0586, -0.1117,  ..., -0.4943, -0.6546,  0.6617]],\n",
      "\n",
      "         [[-0.3665,  0.3408, -0.6133,  ...,  0.1938, -0.6681,  0.5929],\n",
      "          [ 0.8269,  1.7861, -1.1207,  ..., -0.0885,  0.2791,  1.4721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0985, -1.2861, -1.2531,  ...,  0.3609, -1.4022, -0.4444],\n",
      "          [-0.1038,  0.9623, -0.7062,  ..., -0.3340, -0.3050,  0.8792]],\n",
      "\n",
      "         [[-0.9787, -1.4207, -0.9908,  ...,  0.2989, -0.0159, -1.0060],\n",
      "          [ 0.0507,  0.6634, -0.2642,  ..., -0.4959, -0.7944,  0.7687]],\n",
      "\n",
      "         [[-0.1970,  0.2371, -0.0115,  ...,  0.0049, -0.8135,  0.1201],\n",
      "          [ 0.3364,  0.9047, -0.2037,  ..., -0.3705, -0.2893,  0.6787]]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[-0.9552,  0.6594, -6.5403,  ..., -0.7144,  0.0906,  0.3369],\n",
      "         [-2.5251,  1.3955, -0.8914,  ..., -2.1363,  0.0271,  1.1132],\n",
      "         [-3.7148,  0.6796, -0.8710,  ..., -2.6492,  0.5694, -0.1085],\n",
      "         ...,\n",
      "         [-2.2403, -0.7594,  0.5414,  ..., -3.0426,  0.8895, -0.0546],\n",
      "         [-1.6945, -0.6326, -0.8632,  ..., -4.0678,  1.7219,  0.6481],\n",
      "         [-2.9625,  0.7451, -0.8037,  ..., -2.5048,  0.3125,  0.5537]],\n",
      "\n",
      "        [[-0.5150,  0.8150, -6.5015,  ..., -0.5377, -0.4171,  0.1350],\n",
      "         [-2.9979,  1.0930, -0.2619,  ..., -3.1811, -1.0048, -1.8349],\n",
      "         [-2.8788,  0.5405, -0.0789,  ..., -2.3969, -0.7016, -0.7332],\n",
      "         ...,\n",
      "         [-1.7194,  1.5158,  1.0070,  ..., -2.8931, -2.3309,  1.1685],\n",
      "         [ 0.0717, -0.1039,  0.5084,  ..., -2.1932,  0.0751,  2.8236],\n",
      "         [-2.4774,  0.7563, -0.7502,  ..., -2.1312, -0.0685,  0.8700]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.0455,  0.6529,  0.6297,  ...,  0.4139, -0.9381,  0.6769],\n",
      "         [-3.1104, -3.7282, -2.3953,  ..., -0.9155, -0.8280, -1.7070],\n",
      "         [-0.9324, -2.9333, -2.3249,  ..., -0.8455, -0.0326, -0.6998],\n",
      "         ...,\n",
      "         [-1.9000, -1.1028, -1.1281,  ..., -0.2809,  2.0206, -1.0802],\n",
      "         [-1.1088, -1.0420, -2.4026,  ..., -0.4478,  0.7391, -0.0354],\n",
      "         [ 0.7349,  0.6742, -2.6697,  ..., -0.5114,  1.5155,  2.0246]],\n",
      "\n",
      "        [[-0.0799,  0.7813,  0.4918,  ...,  0.6888, -0.7680,  0.9805],\n",
      "         [-2.8720, -1.0602, -2.3610,  ..., -2.1143,  0.9664, -1.1212],\n",
      "         [-1.4705, -2.1384, -1.9955,  ..., -0.9722,  1.5909, -0.1668],\n",
      "         ...,\n",
      "         [-2.9884, -1.1566, -2.5215,  ...,  1.1460,  0.7120, -0.6320],\n",
      "         [-3.3666, -0.7966, -3.3154,  ...,  0.5316,  1.7058,  2.1950],\n",
      "         [ 0.6626,  0.8537, -2.7251,  ..., -0.0901,  1.5883,  2.3840]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0455,  0.6529,  0.6297,  ...,  1.0165, -1.6055,  0.0557],\n",
      "          [-0.9141, -1.5101, -0.8415,  ...,  0.4139, -0.9381,  0.6769]],\n",
      "\n",
      "         [[-3.1104, -3.7282, -2.3953,  ..., -1.6195,  0.7426, -3.2794],\n",
      "          [-1.2694,  0.3821, -0.5687,  ..., -0.9155, -0.8280, -1.7070]],\n",
      "\n",
      "         [[-0.9324, -2.9333, -2.3249,  ..., -1.0254,  1.8158, -1.8835],\n",
      "          [-1.5265, -0.3901,  0.2734,  ..., -0.8455, -0.0326, -0.6998]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9000, -1.1028, -1.1281,  ..., -1.2688, -0.0851, -2.3190],\n",
      "          [-2.4374,  0.0718, -2.7276,  ..., -0.2809,  2.0206, -1.0802]],\n",
      "\n",
      "         [[-1.1088, -1.0420, -2.4026,  ..., -1.0658,  0.1932, -1.7012],\n",
      "          [-2.3622, -0.5291, -1.9931,  ..., -0.4478,  0.7391, -0.0354]],\n",
      "\n",
      "         [[ 0.7349,  0.6742, -2.6697,  ..., -1.4630, -0.1686, -2.5682],\n",
      "          [-0.1401, -0.9712, -2.3801,  ..., -0.5114,  1.5155,  2.0246]]],\n",
      "\n",
      "\n",
      "        [[[-0.0799,  0.7813,  0.4918,  ...,  1.2364, -1.9500, -0.1275],\n",
      "          [-0.4080, -1.5069, -0.8504,  ...,  0.6888, -0.7680,  0.9805]],\n",
      "\n",
      "         [[-2.8720, -1.0602, -2.3610,  ..., -2.3225, -0.0351, -2.7432],\n",
      "          [-0.2305, -0.5940, -1.1570,  ..., -2.1143,  0.9664, -1.1212]],\n",
      "\n",
      "         [[-1.4705, -2.1384, -1.9955,  ..., -0.6524, -1.8025, -1.8321],\n",
      "          [-1.7742, -0.6800, -0.2172,  ..., -0.9722,  1.5909, -0.1668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9884, -1.1566, -2.5215,  ..., -0.5054, -1.0314, -3.4883],\n",
      "          [-1.9535,  0.5573, -2.1564,  ...,  1.1460,  0.7120, -0.6320]],\n",
      "\n",
      "         [[-3.3666, -0.7966, -3.3154,  ...,  0.7587, -0.6289, -3.4848],\n",
      "          [-1.4099, -2.0919, -1.5870,  ...,  0.5316,  1.7058,  2.1950]],\n",
      "\n",
      "         [[ 0.6626,  0.8537, -2.7251,  ..., -1.1831, -0.7083, -2.7717],\n",
      "          [ 0.4486, -1.1639, -2.1203,  ..., -0.0901,  1.5883,  2.3840]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8947,  0.0412, -1.2359,  ...,  0.4410, -0.3965,  0.0106],\n",
      "         [-1.9196,  0.3326,  0.8482,  ..., -1.5790, -1.1817, -1.0156],\n",
      "         [-2.1664,  0.3959,  0.7476,  ..., -2.1767, -0.6488,  0.1889],\n",
      "         ...,\n",
      "         [-1.6009,  0.4887, -0.4818,  ..., -1.1268,  0.4111,  0.7892],\n",
      "         [-0.1528,  1.1728, -0.5164,  ..., -0.4340,  0.1499,  1.6704],\n",
      "         [ 1.0253,  1.4222, -0.1805,  ..., -0.6130, -0.5380,  1.6164]],\n",
      "\n",
      "        [[-0.6736, -0.0718, -1.1724,  ...,  0.2001, -0.5481,  0.0232],\n",
      "         [-1.8698, -1.2184,  0.2913,  ..., -1.1398, -1.3523, -0.7851],\n",
      "         [-1.3725, -0.8212,  0.1984,  ..., -1.8218, -1.4800, -0.2956],\n",
      "         ...,\n",
      "         [-0.5946,  0.5680,  0.8938,  ..., -1.6653,  0.8218,  1.1902],\n",
      "         [ 1.2800,  1.9566,  0.2540,  ..., -1.2290,  0.5257,  1.2667],\n",
      "         [ 1.3511,  1.3329, -0.0782,  ..., -0.8454, -0.7400,  1.5966]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.8947,  0.0412, -1.2359,  ...,  1.5140, -1.9812, -2.5532],\n",
      "          [-0.2951, -1.6086, -0.6381,  ...,  0.4410, -0.3965,  0.0106]],\n",
      "\n",
      "         [[-1.9196,  0.3326,  0.8482,  ..., -2.3348,  1.3935,  1.1452],\n",
      "          [-0.5277,  0.1234,  0.7865,  ..., -1.5790, -1.1817, -1.0156]],\n",
      "\n",
      "         [[-2.1664,  0.3959,  0.7476,  ..., -2.0817,  0.2852,  0.8173],\n",
      "          [-0.8414,  0.5154, -0.4553,  ..., -2.1767, -0.6488,  0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6009,  0.4887, -0.4818,  ..., -1.8165,  1.4764,  0.5091],\n",
      "          [-0.6869,  0.4007, -1.5818,  ..., -1.1268,  0.4111,  0.7892]],\n",
      "\n",
      "         [[-0.1528,  1.1728, -0.5164,  ..., -1.3611,  1.0621,  1.1810],\n",
      "          [-0.7595, -0.1699, -1.5305,  ..., -0.4340,  0.1499,  1.6704]],\n",
      "\n",
      "         [[ 1.0253,  1.4222, -0.1805,  ..., -0.6989,  0.4721,  2.6129],\n",
      "          [-1.2381, -0.4573, -1.7561,  ..., -0.6130, -0.5380,  1.6164]]],\n",
      "\n",
      "\n",
      "        [[[-0.6736, -0.0718, -1.1724,  ...,  1.4816, -1.7920, -2.5177],\n",
      "          [-0.3929, -1.5120, -0.5353,  ...,  0.2001, -0.5481,  0.0232]],\n",
      "\n",
      "         [[-1.8698, -1.2184,  0.2913,  ..., -1.5227,  1.9764,  0.6389],\n",
      "          [-0.4202,  0.4572, -1.0780,  ..., -1.1398, -1.3523, -0.7851]],\n",
      "\n",
      "         [[-1.3725, -0.8212,  0.1984,  ..., -2.1553,  1.7041,  0.7166],\n",
      "          [-1.0124,  0.9351, -0.0954,  ..., -1.8218, -1.4800, -0.2956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5946,  0.5680,  0.8938,  ..., -2.1904,  1.7986,  1.0902],\n",
      "          [-1.3820,  1.0268, -1.0041,  ..., -1.6653,  0.8218,  1.1902]],\n",
      "\n",
      "         [[ 1.2800,  1.9566,  0.2540,  ..., -1.6180,  1.6176,  2.5636],\n",
      "          [-2.0592,  0.7059, -1.3359,  ..., -1.2290,  0.5257,  1.2667]],\n",
      "\n",
      "         [[ 1.3511,  1.3329, -0.0782,  ..., -0.5836,  0.6491,  2.6554],\n",
      "          [-1.3686, -0.2348, -1.7438,  ..., -0.8454, -0.7400,  1.5966]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8837e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0706e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3443e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[ 3.8307e-01,  1.8837e-02, -1.0314e+00,  ...,  6.4335e-01,\n",
      "          -3.1830e-01, -1.7296e+00],\n",
      "         [ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ...,  1.5973e+00,\n",
      "           1.1907e+00, -9.0454e-01],\n",
      "         [-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -5.3627e-01,\n",
      "          -1.0456e+00, -1.6301e+00],\n",
      "         ...,\n",
      "         [-1.7466e-01,  3.0706e-02,  7.5225e-01,  ..., -1.3217e+00,\n",
      "          -1.3415e+00, -3.8328e-01],\n",
      "         [ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -1.6600e-01,\n",
      "          -6.5011e-01,  2.1798e-02],\n",
      "         [-2.4311e-01,  1.6726e+00,  1.6682e-01,  ...,  1.3443e-03,\n",
      "          -1.6754e+00,  3.1771e-01]],\n",
      "\n",
      "        [[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ...,  6.4928e-01,\n",
      "          -3.2944e-01, -2.4185e+00],\n",
      "         [ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.8623e+00,\n",
      "          -1.1230e+00,  3.5013e-01],\n",
      "         [ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ...,  6.4975e-01,\n",
      "          -7.3862e-01, -2.1510e+00],\n",
      "         ...,\n",
      "         [ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  1.7637e+00,\n",
      "           9.1331e-01, -1.7033e+00],\n",
      "         [ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ...,  9.8096e-01,\n",
      "           8.6736e-01, -2.3894e+00],\n",
      "         [ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ...,  6.2708e-01,\n",
      "          -1.3601e+00, -3.9984e-01]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.8307e-01,  1.8837e-02, -1.0314e+00,  ..., -8.0955e-01,\n",
      "           -2.8557e-01, -2.3318e-01],\n",
      "          [-9.9661e-02,  3.1722e-01, -3.0517e-01,  ...,  6.4335e-01,\n",
      "           -3.1830e-01, -1.7296e+00]],\n",
      "\n",
      "         [[ 1.5897e+00,  1.3689e-01, -6.8915e-01,  ..., -7.9549e-01,\n",
      "           -6.9279e-01, -1.8082e-01],\n",
      "          [-9.9201e-01,  9.4938e-01,  4.4198e-02,  ...,  1.5973e+00,\n",
      "            1.1907e+00, -9.0454e-01]],\n",
      "\n",
      "         [[-5.8138e-01,  6.7943e-01, -1.3203e+00,  ..., -1.8905e+00,\n",
      "            1.6226e-01, -1.2953e+00],\n",
      "          [-7.0312e-01, -6.4926e-01, -5.0913e-01,  ..., -5.3627e-01,\n",
      "           -1.0456e+00, -1.6301e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7466e-01,  3.0706e-02,  7.5225e-01,  ..., -1.9281e+00,\n",
      "            1.1489e+00, -2.4530e-01],\n",
      "          [-7.6226e-02,  8.5814e-01, -1.5467e+00,  ..., -1.3217e+00,\n",
      "           -1.3415e+00, -3.8328e-01]],\n",
      "\n",
      "         [[ 1.5170e-01,  5.1089e-01,  1.3993e-01,  ..., -2.4168e+00,\n",
      "            3.3385e-01, -6.2115e-02],\n",
      "          [-1.6390e+00, -1.6085e-01, -1.9118e+00,  ..., -1.6600e-01,\n",
      "           -6.5011e-01,  2.1798e-02]],\n",
      "\n",
      "         [[-2.4311e-01,  1.6726e+00,  1.6682e-01,  ..., -1.0481e+00,\n",
      "           -2.7634e+00,  2.2741e-01],\n",
      "          [-1.4603e+00,  3.1239e-02,  3.8892e-01,  ...,  1.3443e-03,\n",
      "           -1.6754e+00,  3.1771e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7844e-01, -3.1772e-01, -1.0617e+00,  ..., -7.8511e-01,\n",
      "           -3.2510e-01, -2.1300e-01],\n",
      "          [-3.9893e-01,  6.1469e-01, -3.9206e-01,  ...,  6.4928e-01,\n",
      "           -3.2944e-01, -2.4185e+00]],\n",
      "\n",
      "         [[ 5.9122e-01, -2.2648e-01,  1.7474e-01,  ..., -1.6488e+00,\n",
      "           -8.6854e-01, -8.0783e-01],\n",
      "          [-2.1516e+00, -2.4247e-01, -8.1713e-01,  ..., -1.8623e+00,\n",
      "           -1.1230e+00,  3.5013e-01]],\n",
      "\n",
      "         [[ 1.1642e-01,  1.2460e+00,  7.7942e-02,  ..., -1.3121e+00,\n",
      "           -6.7044e-01, -1.1324e+00],\n",
      "          [ 4.3930e-01,  3.4082e-01, -1.2243e+00,  ...,  6.4975e-01,\n",
      "           -7.3862e-01, -2.1510e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1291e+00, -1.3637e+00, -1.5779e+00,  ...,  8.5980e-01,\n",
      "            3.2796e-01, -1.9442e+00],\n",
      "          [-8.9502e-01,  9.7357e-01,  8.5447e-01,  ...,  1.7637e+00,\n",
      "            9.1331e-01, -1.7033e+00]],\n",
      "\n",
      "         [[ 1.5909e+00, -1.4922e+00,  1.0060e+00,  ..., -1.5965e+00,\n",
      "           -3.9380e-01, -4.3585e-01],\n",
      "          [-2.2103e+00,  4.4127e-01,  1.1554e+00,  ...,  9.8096e-01,\n",
      "            8.6736e-01, -2.3894e+00]],\n",
      "\n",
      "         [[ 1.8451e-01,  1.2740e+00,  4.2857e-01,  ..., -1.1366e+00,\n",
      "           -2.8409e+00,  4.6711e-01],\n",
      "          [-1.9576e+00,  2.0176e-01, -4.1035e-02,  ...,  6.2708e-01,\n",
      "           -1.3601e+00, -3.9984e-01]]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          ...,\n",
      "          [ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4397e-02, -6.9034e-02]],\n",
      "\n",
      "         [[-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3793e-03,\n",
      "           -5.2249e-01, -4.2095e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5678e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01],\n",
      "          ...,\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01],\n",
      "          [-1.0678e+00,  9.0885e-02, -4.5401e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6663e-03, -5.7117e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [ 4.5120e-01, -5.8035e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          ...,\n",
      "          [ 3.3361e-01,  1.5917e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01]],\n",
      "\n",
      "         [[-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00],\n",
      "          ...,\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1643e-01, -2.0784e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6103e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]],\n",
      "       grad_fn=<ScaledDotProductFlashAttentionForCpuBackward0>)\n",
      "tensor([[[[ 3.7393e-01,  3.7078e-01, -7.5553e-01,  ..., -9.4280e-01,\n",
      "           -6.5765e-01, -1.4711e-01],\n",
      "          [-7.7230e-01, -1.1852e-01, -8.0275e-02,  ..., -1.3793e-03,\n",
      "           -5.2249e-01, -4.2095e-01]],\n",
      "\n",
      "         [[ 3.9396e-01,  4.7658e-02, -1.0277e+00,  ..., -8.4926e-01,\n",
      "           -2.7815e-01, -2.6628e-01],\n",
      "          [-4.6209e-01, -1.2680e-01, -2.5711e-01,  ...,  1.3235e-01,\n",
      "           -4.1385e-01, -1.3744e+00]],\n",
      "\n",
      "         [[ 9.9586e-01,  2.4414e-01, -8.3459e-01,  ..., -8.5795e-01,\n",
      "           -4.3860e-01, -2.1582e-01],\n",
      "          [-1.7985e-01, -2.6037e-01,  3.5678e-01,  ...,  2.4736e-01,\n",
      "           -1.6626e-01, -7.0940e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4504e+00, -1.2077e-01, -4.8160e-01,  ..., -1.6701e+00,\n",
      "            6.3807e-01, -8.3788e-02],\n",
      "          [-6.2069e-01,  2.5298e-01, -7.8416e-01,  ...,  8.6186e-02,\n",
      "           -6.9561e-01, -8.5675e-01]],\n",
      "\n",
      "         [[ 3.8821e-01,  1.4150e-01, -1.5051e-01,  ..., -1.5785e+00,\n",
      "            4.1589e-01, -1.8024e-01],\n",
      "          [-9.1553e-01,  1.4648e-01, -5.5621e-02,  ...,  1.8643e-01,\n",
      "           -1.0965e+00, -4.8097e-01]],\n",
      "\n",
      "         [[ 1.0467e-01,  5.5196e-01,  1.0818e-01,  ..., -2.0373e+00,\n",
      "            8.4397e-02, -6.9034e-02],\n",
      "          [-1.0678e+00,  9.0885e-02, -4.5401e-02,  ...,  1.5424e-01,\n",
      "           -1.1762e+00, -2.9385e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9445e-01,  9.6663e-03, -5.7117e-01,  ..., -9.7640e-01,\n",
      "           -9.0948e-01, -1.3761e-01],\n",
      "          [-1.0884e+00,  2.0838e-01, -5.0948e-01,  ...,  2.2845e-01,\n",
      "           -8.2075e-01, -1.1496e+00]],\n",
      "\n",
      "         [[ 4.7672e-01, -2.3672e-01, -8.9246e-01,  ..., -8.9927e-01,\n",
      "           -3.9088e-01, -3.1635e-01],\n",
      "          [-3.4296e-01,  5.0833e-01, -8.6644e-01,  ...,  3.3008e-01,\n",
      "           -5.5070e-01, -1.8440e+00]],\n",
      "\n",
      "         [[ 4.5120e-01, -5.8035e-02, -6.8736e-01,  ..., -1.0352e+00,\n",
      "           -4.7996e-01, -4.5624e-01],\n",
      "          [-3.2602e-01,  6.0671e-01, -7.5711e-01,  ...,  4.7493e-01,\n",
      "           -4.6589e-01, -2.0454e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3361e-01,  1.5917e-03, -1.0108e+00,  ..., -1.5704e+00,\n",
      "           -3.9079e-01, -2.1742e-01],\n",
      "          [-1.7399e+00,  4.6359e-01,  6.5213e-01,  ...,  9.0025e-01,\n",
      "            3.1643e-01, -2.0784e+00]],\n",
      "\n",
      "         [[ 1.0123e+00, -1.1147e+00, -1.3032e+00,  ...,  3.4082e-01,\n",
      "            1.3298e-01, -1.5481e+00],\n",
      "          [-1.8375e+00,  2.6226e-01,  3.7727e-02,  ...,  6.6286e-01,\n",
      "           -1.0588e+00, -7.6781e-01]],\n",
      "\n",
      "         [[ 1.4273e+00, -1.2951e+00,  5.7719e-01,  ..., -1.2490e+00,\n",
      "           -4.1355e-01, -5.8558e-01],\n",
      "          [-1.6402e+00,  3.1250e-01, -6.6103e-04,  ...,  6.6493e-01,\n",
      "           -9.1110e-01, -1.0382e+00]]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[-0.0897,  0.4657],\n",
      "        [-0.1539,  0.4561]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from chop import MaseGraph\n",
    "import chop.passes as passes\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "\n",
    "mg = MaseGraph(\n",
    "    model,\n",
    "    hf_input_names=[\n",
    "        \"input_ids\",\n",
    "        \"attention_mask\",\n",
    "        \"labels\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "mg, _ = passes.init_metadata_analysis_pass(mg)\n",
    "mg, _ = passes.add_common_metadata_analysis_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have previously ran the tutorial on LoRA Finetuning, run the following cell to import the fine tuned checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/hv122/adls_group_14/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from chop import MaseGraph\n",
    "import chop.passes as passes\n",
    "\n",
    "mg = MaseGraph.from_checkpoint(f\"{Path.home()}/tutorial_2_lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Training Quantization (PTQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we simply quantize the model and evaluate the effect in its accuracy. First, let's evaluate the model accuracy before quantization (if you're coming from Tutorial 2, this should be the same as the post-LoRA evaluation accuracy). As seen in Tutorial 2, we can use the `get_tokenized_dataset` and `get_trainer` utilities to generate a HuggingFace `Trainer` instance for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.83436\n"
     ]
    }
   ],
   "source": [
    "from chop.tools import get_tokenized_dataset, get_trainer\n",
    "\n",
    "dataset, tokenizer = get_tokenized_dataset(\n",
    "    dataset=dataset_name,\n",
    "    checkpoint=tokenizer_checkpoint,\n",
    "    return_tokenizer=True,\n",
    ")\n",
    "\n",
    "trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Evaluate accuracy\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the quantization pass, we pass a quantization configuration dictionary as argument. This defines the quantization mode, numerical format and precision for each operator in the graph. We'll run the quantization in \"by type\" mode, meaning nodes are quantized according to their `mase_op`. Other modes include by name and by regex name. We'll quantize all activations, weights and biases in the model to fixed-point with the same precision. This may be sub-optimal, but works as an example. In future tutorials, we'll see how to run the `search` flow in `Mase` to find optimal quantization configurations to minimize accuracy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chop.passes as passes\n",
    "\n",
    "quantization_config = {\n",
    "    \"by\": \"type\",\n",
    "    \"default\": {\n",
    "        \"config\": {\n",
    "            \"name\": None,\n",
    "        }\n",
    "    },\n",
    "    \"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "mg, _ = passes.quantize_transform_pass(\n",
    "    mg,\n",
    "    pass_args=quantization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the immediate effect of quantization on the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9375' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.81572\n"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    ")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the current checkpoint for future reference (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to /homes/hv122/tutorial_3_ptq.pt, /homes/hv122/tutorial_3_ptq.mz\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to /homes/hv122/tutorial_3_ptq.pt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaving full model format\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseMetadata to /homes/hv122/tutorial_3_ptq.mz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "mg.export(f\"{Path.home()}/tutorial_3_ptq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization-Aware Training (QAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have seen in the last section that quantization can lead to a significant drop in accuracy. Next, we'll run QAT to evaluate whether this performance gap can be reduced. To run QAT in Mase, all you need to do is include the model back in your training loop after running the quantization pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.410900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.407400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.394100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.388800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation accuracy: 0.83672\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation accuracy: {eval_results['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the accuracy of the quantized model can match (or sometimes exceed) the full precision model, with a much lower memory requirement to store the weights. Finally, save the final checkpoint for future tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseGraph to /homes/hv122/tutorial_3_qat.pt, /homes/hv122/tutorial_3_qat.mz\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting GraphModule to /homes/hv122/tutorial_3_qat.pt\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSaving full model format\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mExporting MaseMetadata to /homes/hv122/tutorial_3_qat.mz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "mg.export(f\"{Path.home()}/tutorial_3_qat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bit-width Task\n",
    "\n",
    "Check the format the data is in - does it require more fractional or integer bits for precise representation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name                               | Shape                | Mean       | Std        | Range\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "bert.encoder.layer.0.attention.self.query | [128, 128]           | -0.0004    | 0.0725     | [-0.3396, 0.3785]\n",
      "bert.encoder.layer.0.attention.self.key  | [128, 128]           | 0.0004     | 0.0710     | [-0.3119, 0.3087]\n",
      "bert.encoder.layer.0.attention.self.value | [128, 128]           | 0.0001     | 0.1006     | [-0.5005, 0.5147]\n",
      "bert.encoder.layer.0.attention.output.dense | [128, 128]           | 0.0000     | 0.1031     | [-0.6122, 0.4754]\n",
      "bert.encoder.layer.0.intermediate.dense  | [512, 128]           | -0.0012    | 0.0743     | [-0.6432, 0.6168]\n",
      "bert.encoder.layer.0.output.dense        | [128, 512]           | -0.0002    | 0.0618     | [-1.2637, 1.1070]\n",
      "bert.encoder.layer.1.attention.self.query | [128, 128]           | -0.0008    | 0.1032     | [-0.4905, 0.3709]\n",
      "bert.encoder.layer.1.attention.self.key  | [128, 128]           | 0.0001     | 0.0750     | [-0.3495, 0.3328]\n",
      "bert.encoder.layer.1.attention.self.value | [128, 128]           | 0.0002     | 0.0987     | [-0.3999, 0.3908]\n",
      "bert.encoder.layer.1.attention.output.dense | [128, 128]           | 0.0000     | 0.1469     | [-0.9783, 1.1747]\n",
      "bert.encoder.layer.1.intermediate.dense  | [512, 128]           | -0.0013    | 0.0811     | [-0.5476, 0.9399]\n",
      "bert.encoder.layer.1.output.dense        | [128, 512]           | -0.0000    | 0.0926     | [-0.6439, 0.5499]\n",
      "bert.pooler.dense                        | [128, 128]           | 0.0001     | 0.0856     | [-0.7431, 0.7593]\n",
      "classifier                               | [2, 128]             | 0.0005     | 0.0288     | [-0.0683, 0.0843]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "print(f\"{'Layer Name':<40} | {'Shape':<20} | {'Mean':<10} | {'Std':<10} | {'Range'}\")\n",
    "print(\"-\" * 105)\n",
    "\n",
    "for name, module in mg.model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        weights = module.weight.data\n",
    "        \n",
    "        w_min = weights.min().item()\n",
    "        w_max = weights.max().item()\n",
    "        w_mean = weights.mean().item()\n",
    "        w_std = weights.std().item()\n",
    "        \n",
    "        print(f\"{name:<40} | {str(list(weights.shape)):<20} | {w_mean:<10.4f} | {w_std:<10.4f} | [{w_min:.4f}, {w_max:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we can limit the integer width quite strictly, we'll explore a limited area of integer width, and then explore the rest of space left to us in the 32 bit-width with fractional bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned accuracy: 0.83672\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "result_log = []\n",
    "first_run = {}\n",
    "\n",
    "# Evaluate accuracy before PTQ\n",
    "pre_ptq_eval_results = trainer.evaluate()\n",
    "first_run[\"Finetuned Accuracy\"] = pre_ptq_eval_results['eval_accuracy']\n",
    "print(f\"Finetuned accuracy: {pre_ptq_eval_results['eval_accuracy']}\")\n",
    "result_log.append(first_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_whole_int_loop():\n",
    "  for width in range(5, 12):\n",
    "    mg = MaseGraph.from_checkpoint(f\"{Path.home()}/tutorial_2_lora\")\n",
    "    current_run = {\n",
    "                \"Total Width\": width,\n",
    "                \"Fractional Width\": 4, \n",
    "                \"Integer Bits\": width - 4\n",
    "            }\n",
    "    dataset, tokenizer = get_tokenized_dataset(\n",
    "        dataset=dataset_name,\n",
    "        checkpoint=tokenizer_checkpoint,\n",
    "        return_tokenizer=True,\n",
    "    )\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model=mg.model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "    )\n",
    "\n",
    "    import chop.passes as passes\n",
    "\n",
    "    quantization_config = {\n",
    "        \"by\": \"type\",\n",
    "        \"default\": {\n",
    "            \"config\": {\n",
    "                \"name\": None,\n",
    "            }\n",
    "        },\n",
    "        \"linear\": {\n",
    "            \"config\": {\n",
    "                \"name\": \"integer\",\n",
    "                # data\n",
    "                \"data_in_width\": width,\n",
    "                \"data_in_frac_width\": 4,\n",
    "                # weight\n",
    "                \"weight_width\": width,\n",
    "                \"weight_frac_width\": 4,\n",
    "                # bias\n",
    "                \"bias_width\": width,\n",
    "                \"bias_frac_width\": 4,\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    mg, _ = passes.quantize_transform_pass(\n",
    "        mg,\n",
    "        pass_args=quantization_config,\n",
    "    )\n",
    "\n",
    "    trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    "  )\n",
    "    post_ptq_result = trainer.evaluate()\n",
    "    current_run[\"Post-PTQ Accuracy\"] = post_ptq_result['eval_accuracy']\n",
    "    print(f\"PTQ accuracy: {post_ptq_result['eval_accuracy']}\")\n",
    "\n",
    "    trainer.train()\n",
    "    post_qat_result = trainer.evaluate()\n",
    "    current_run[\"Post-QAT Accuracy\"] = post_qat_result['eval_accuracy']\n",
    "    print(f\"QAT accuracy: {post_qat_result['eval_accuracy']}\")\n",
    "\n",
    "    result_log.append(current_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.71908\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2786' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2786/3125 01:05 < 00:07, 42.49 it/s, Epoch 0.89/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.455300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.455600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.430700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.423000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "execute_whole_int_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Finetuned Accuracy  Total Width  Fractional Width  Integer Bits  \\\n",
      "0             0.83672          NaN               NaN           NaN   \n",
      "1                 NaN          5.0               4.0           1.0   \n",
      "2                 NaN          6.0               4.0           2.0   \n",
      "3                 NaN          7.0               4.0           3.0   \n",
      "4                 NaN          8.0               4.0           4.0   \n",
      "5                 NaN          9.0               4.0           5.0   \n",
      "6                 NaN         10.0               4.0           6.0   \n",
      "7                 NaN         11.0               4.0           7.0   \n",
      "\n",
      "   Post-PTQ Accuracy  Post-QAT Accuracy  \n",
      "0                NaN                NaN  \n",
      "1            0.71908            0.81716  \n",
      "2            0.76848            0.83436  \n",
      "3            0.78336            0.83592  \n",
      "4            0.81572            0.83672  \n",
      "5            0.81768            0.83676  \n",
      "6            0.81768            0.83652  \n",
      "7            0.81768            0.83652  \n"
     ]
    }
   ],
   "source": [
    "int_sweep_df = DataFrame(result_log)\n",
    "print(int_sweep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(int_sweep_df[\"Integer Bits\"], int_sweep_df[\"Post-PTQ Accuracy\"], marker=\"o\", label=\"Post-PTQ Accuracy\")\n",
    "plt.plot(int_sweep_df[\"Integer Bits\"], int_sweep_df[\"Post-QAT Accuracy\"], marker=\"x\", label=\"Post-QAT Accuracy\")\n",
    "plt.title(\"Post-Quantization Accuracy vs Integer Bits\")\n",
    "plt.xlabel(\"Integer Bits\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"tut3_integer_bits.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_result_log = []\n",
    "frac_result_log.append(first_run)\n",
    "\n",
    "def execute_whole_frac_loop():\n",
    "  for width in range(3, 28):\n",
    "    mg = MaseGraph.from_checkpoint(f\"{Path.home()}/tutorial_2_lora\")\n",
    "    current_run = {\n",
    "                \"Total Width\": width + 5,\n",
    "                \"Fractional Width\": width, \n",
    "                \"Integer Bits\": 5\n",
    "            }\n",
    "    dataset, tokenizer = get_tokenized_dataset(\n",
    "        dataset=dataset_name,\n",
    "        checkpoint=tokenizer_checkpoint,\n",
    "        return_tokenizer=True,\n",
    "    )\n",
    "\n",
    "    trainer = get_trainer(\n",
    "        model=mg.model,\n",
    "        tokenized_dataset=dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        evaluate_metric=\"accuracy\",\n",
    "    )\n",
    "\n",
    "    import chop.passes as passes\n",
    "\n",
    "    quantization_config = {\n",
    "        \"by\": \"type\",\n",
    "        \"default\": {\n",
    "            \"config\": {\n",
    "                \"name\": None,\n",
    "            }\n",
    "        },\n",
    "        \"linear\": {\n",
    "            \"config\": {\n",
    "                \"name\": \"integer\",\n",
    "                # data\n",
    "                \"data_in_width\": width + 5,\n",
    "                \"data_in_frac_width\": width,\n",
    "                # weight\n",
    "                \"weight_width\": width + 5,\n",
    "                \"weight_frac_width\": width,\n",
    "                # bias\n",
    "                \"bias_width\": width + 5,\n",
    "                \"bias_frac_width\": width,\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    mg, _ = passes.quantize_transform_pass(\n",
    "        mg,\n",
    "        pass_args=quantization_config,\n",
    "    )\n",
    "\n",
    "    trainer = get_trainer(\n",
    "    model=mg.model,\n",
    "    tokenized_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    evaluate_metric=\"accuracy\",\n",
    "  )\n",
    "    post_ptq_result = trainer.evaluate()\n",
    "    current_run[\"Post-PTQ Accuracy\"] = post_ptq_result['eval_accuracy']\n",
    "    print(f\"PTQ accuracy: {post_ptq_result['eval_accuracy']}\")\n",
    "\n",
    "    trainer.train()\n",
    "    post_qat_result = trainer.evaluate()\n",
    "    current_run[\"Post-QAT Accuracy\"] = post_qat_result['eval_accuracy']\n",
    "    print(f\"QAT accuracy: {post_qat_result['eval_accuracy']}\")\n",
    "\n",
    "    frac_result_log.append(current_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n",
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.69176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.567600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.470900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.415400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.424900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.411700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.82964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.81768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.407900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.414400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.388500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.82956\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.405300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.400700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.410700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.385800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.388400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.388300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83172\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.405300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.400200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.408600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.385300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.384200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83092\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.400100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.406200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.384100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.384200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.8346\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.8388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83336\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83472\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.834\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83432\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83432\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:12, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:59]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode finfo not found in loaded metadata.\u001b[0m\n",
      "\u001b[33mWARNING \u001b[0m \u001b[34mNode getattr_2 not found in loaded metadata.\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mTokenizing dataset imdb with AutoTokenizer for bert-base-uncased.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since imdb couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'plain_text' at /homes/hv122/.cache/huggingface/datasets/imdb/plain_text/0.0.0/e6281661ce1c48d982bc483cf8a173c1bbeb5d31 (last modified on Mon Jan 26 16:13:14 2026).\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/vol/bitbucket/hv122/adls_group_14/src/chop/tools/huggingface.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 02:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ accuracy: 0.83436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 01:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.384500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT accuracy: 0.83888\n"
     ]
    }
   ],
   "source": [
    "execute_whole_frac_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Finetuned Accuracy  Total Width  Fractional Width  Integer Bits  \\\n",
      "0              0.83672          NaN               NaN           NaN   \n",
      "1                  NaN          6.0               1.0           5.0   \n",
      "2                  NaN          6.0               1.0           5.0   \n",
      "3                  NaN          7.0               2.0           5.0   \n",
      "4                  NaN          8.0               3.0           5.0   \n",
      "5                  NaN          9.0               4.0           5.0   \n",
      "6                  NaN         10.0               5.0           5.0   \n",
      "7                  NaN         11.0               6.0           5.0   \n",
      "8                  NaN         12.0               7.0           5.0   \n",
      "9                  NaN         13.0               8.0           5.0   \n",
      "10                 NaN         14.0               9.0           5.0   \n",
      "11                 NaN         15.0              10.0           5.0   \n",
      "12                 NaN         16.0              11.0           5.0   \n",
      "13                 NaN         17.0              12.0           5.0   \n",
      "14                 NaN         18.0              13.0           5.0   \n",
      "15                 NaN         19.0              14.0           5.0   \n",
      "16                 NaN         20.0              15.0           5.0   \n",
      "17                 NaN         21.0              16.0           5.0   \n",
      "18                 NaN         22.0              17.0           5.0   \n",
      "19                 NaN         23.0              18.0           5.0   \n",
      "20                 NaN         24.0              19.0           5.0   \n",
      "21                 NaN         25.0              20.0           5.0   \n",
      "22                 NaN         26.0              21.0           5.0   \n",
      "23                 NaN         27.0              22.0           5.0   \n",
      "24                 NaN         28.0              23.0           5.0   \n",
      "25                 NaN         29.0              24.0           5.0   \n",
      "26                 NaN         30.0              25.0           5.0   \n",
      "27                 NaN         31.0              26.0           5.0   \n",
      "28                 NaN         32.0              27.0           5.0   \n",
      "\n",
      "    Post-PTQ Accuracy  Post-QAT Accuracy  \n",
      "0                 NaN                NaN  \n",
      "1             0.50000            0.50000  \n",
      "2             0.50000            0.50000  \n",
      "3             0.50000            0.50000  \n",
      "4             0.69176            0.82964  \n",
      "5             0.81768            0.83676  \n",
      "6             0.82956            0.83908  \n",
      "7             0.83172            0.83888  \n",
      "8             0.83092            0.83904  \n",
      "9             0.83404            0.83876  \n",
      "10            0.83460            0.83880  \n",
      "11            0.83336            0.83908  \n",
      "12            0.83472            0.83896  \n",
      "13            0.83436            0.83896  \n",
      "14            0.83400            0.83888  \n",
      "15            0.83432            0.83888  \n",
      "16            0.83432            0.83888  \n",
      "17            0.83436            0.83888  \n",
      "18            0.83436            0.83888  \n",
      "19            0.83436            0.83888  \n",
      "20            0.83436            0.83888  \n",
      "21            0.83436            0.83888  \n",
      "22            0.83436            0.83888  \n",
      "23            0.83436            0.83888  \n",
      "24            0.83436            0.83888  \n",
      "25            0.83436            0.83888  \n",
      "26            0.83436            0.83888  \n",
      "27            0.83436            0.83888  \n",
      "28            0.83436            0.83888  \n"
     ]
    }
   ],
   "source": [
    "frac_df = DataFrame(frac_result_log)\n",
    "print(frac_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(frac_df[\"Fractional Width\"], frac_df[\"Post-PTQ Accuracy\"], marker=\"o\", label=\"Post-PTQ Accuracy\")\n",
    "plt.plot(frac_df[\"Fractional Width\"], frac_df[\"Post-QAT Accuracy\"], marker=\"x\", label=\"Post-QAT Accuracy\")\n",
    "plt.title(\"Post-Quantization Accuracy vs Fractional Bits\")\n",
    "plt.xlabel(\"Fractional Bits\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"tut3_fractional_bits.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
